---
title: "Data Wrangling"
author: "Michael W. McCoy"
date: "Last updated on `r format(Sys.time(), '%d %B, %Y')`"
output: html_notebook
---


**Data Wrangling**
This week we will explore data manipulation and techniques for summarizing data using the library `dplyr`. For most of this exercise we will be working with Base R and working within the "Tidyverse"

```{r echo=TRUE}
#You may need to o install the tidyverse using "install.packages("tidyverse",dependencies=TRUE)
library(tidyverse) # loads readr, dplyr and many others libraries useful for working with data including ggplot2
```

In this exercise we will learn to 
  1) Read data from a CSV file
  2) Identify and convert data types in your data file
  3) Manipulate data frames
  4) Extract subsets of data using base R
  5) Extract subsets of data using 'dplyr' in the tidyverse
  6) Add new variables to a data frame, select, sort, aggregate and summarize the data in a            data frame using tidyR.  

**Working with DATA**

*Data set 1: Mammal body mass*

These data were published as a data paper in Ecology and deposited in the Ecological Archives (F. A. Smith, S. K. Lyons, S. K. M. Ernest, K. E. Jones, D. M. Kaufman, T. Dayan, P. A. Marquet, J. H. Brown, and J. P. Haskell. 2003. Body mass of late Quaternary mammals. Ecology 84: 3403.) See the metadata for a description.

Most of the variables are categorical, with multiple named categories. 
  “Continent” includes mammals on islands (“Insular” category) 
  “Oceanic” refers to marine mammals. 
  "Body mass" is reported in grams and is the sole numeric variable. 
  “status” indicates whether a species is:
      currently present in the wild (extant), 
      extinct as of late Pleistocene (extinct), 
      extinct within the last 300 years (historical), 
      or an introduced species (introduction).


*Read data from csv file stored on your computer or on the web*

Start R and read the contents of the file to a data frame. It is best to save your original data as a csv or other delimited text file to ensure there is no hidden formatting that can affect that data that is uploaded into R. 

There are different ways to load your data.  
1. You can use the drop down menus that are available as part of R studio.  However, I do not recommend this becuase there is no text record of htis in your code.

You can use the commands from either base R or from the tidyverse.  I will use both throughout because they are largely interchangeable for most applications.  The `read.csv` function from base R, or the `read_csv` function from the readr package in the tidyverse.  

For example, I would use the below code. You will have to change the file path to match your operating system and file structure...this code is just for example you dont need to run it. More on this below.

  From base R
  mammals <- read.csv("~/Documents/Github/BSC 6936/R tutorial-2/mammals.csv",na.strings="",stringsAsFactors =FALSE)

  Or, from tidyR
  mammals <- read_csv("~/Documents/Github/BSC 6936/R tutorial-2/mammals.csv",na = c(""))



**You need to start modifying and running all the code below**

The following chunk of code provides 3 different ways in base R to read in a data file for example “mammal.csv” into a data frame we wail call my data. The stringsAsFactors = FALSE argument tells R to keep each character variable as-is rather than convert to factors, which are a little harder to work with.

```{r echo=TRUE}
# base R
mydata<-read.csv(file.choose(),stringsAsFactors=FALSE) 
```

To read in data using the readr package from the tidyverse, everything should be the same as above except you use the function read_csv()

```{r}
# using readr package
mydata <- read_csv("/path and directory name/mammals.csv")
```

There also a a few optional arguments that can help save you time and frustration if there are problems with the datafile that are preventing the data from having the correct classification or spelling (more below on data classification). For instance, spaces can be sometimes introduced accidentally during data entry and R will treats “word” and " word" as being different which can lead to analytical issues later on (e.g. you may have too many levels of a factor because “word” and " word" are being read as two different levels of a factor.  To deal with this you can add `strip.white = TRUE` which removes spaces at the start and end of character elements. Another useful option is `na.strings` in Base R and na in readr which tell R to treat both NA and empty strings in columns of character data as missing values rather than as the value "NA". You do not need to specify this in most cases because it is the default setting, but I highlight it here because might in some cases need to alter the value coding for missing values. In other words you could replace "NA" in the code below with your own indicator of missing data (e.g. "." or "no_data"), For example, `read.csv("filename.csv", stringsAsFactors = FALSE,strip.white = TRUE, na.strings = c("no_data", "") ) `

Try filling in the correct information in the chunks below so that you uplaod the mammals data
```{r echo=TRUE, warning=TRUE}
mydata<-read.csv("home/github/mammals.csv",stringsAsFactors=FALSE,strip.white= TRUE,na.strings=c("NA", ""))
```

*Checking your Data*

After you have imported your data there are a variety of tools that you can use to visualize the data frame to make sure it is what you were expecting. Here are a list of the most helpful...

To view small aspects of the data frame
```{r echo=TRUE, warning=TRUE}
mammals             
print(mammals,n=5) 
head(mammals)       
tail(mammals)       
names(mammals)      
rownames(mammals)  
```
You have to be careful here...because sometimes you can accidently remove some of your data if you are not cautious about your naming conventions.  Look at the column labled "continent" in the csv file using excel.  

Now lets look at the data in R.

```{r echo=TRUE, warning=TRUE}
View(mammals)
```

Scroll down to row 3898 and you will notice that the data are missing.  This is a "tip" about data management. Think about conflicts that might occur when analyzing your data and when you are labeling categories.  In this data file ”NA" is used to symbolize North America in the continent column rather than to represent missing data.  So the additional argument added to the read.csv commands (na = c("NA", "")) removes the data for North America. 

You can see this by using the command levels to view the levels of any factor.  We will convert the data to a factor and then view it.
```{r echo=TRUE, warning=TRUE}
levels(factor(mammals$continent))
```

So in this case You will need to modify the argument that identifies missing data to na.strings="“ (or na=”“ if you are using read_csv from the readr package) because in this data file ”NA" is used to symbolize North America in the continent column .

```{r echo=TRUE, warning=TRUE}
mammals<-read.csv("~/GitHub/mammals.csv",stringsAsFactors=FALSE,strip.white=TRUE,na.strings=c(""))
levels(factor(mammals$continent))
```


Here are some other commands that provide useful summaries of the entire data frame

```{r}
str(mammals)                     
is.data.frame(mammals)           
ncol(mammals)                    
nrow(mammals)                    
names(mammals)                   
rownames(mammals)                
```


*Variable types in your data*

When you read your data into R, the program automatically classifies each of your variables (i.e. columns) into data types based on the objects in the column. 

1. Columns with only numbers are made into numeric or integer variables.
2. Columns that have any non-numeric characters (even its supposed to be a numeric data column and there was a data entry error) is read in as either characters (read_csv)  or factors (read.csv). By default, read.csv() converts character variables into factors, which can be annoying to work with. Circumvent this by specifying stringsAsFactors = FALSE in the read.csv() call.

Factors are categorical variables whose categories represent levels. These levels have names, but they additionally have a numeric interpretation. If a variable A has 3 categories “a”, “b”, and “c”, R will order the levels alphabetically, by default, and give them the corresponding numerical interpretations 1, 2, and 3. This will determine the order that the categories appear in graphs and tables. You can always change the order of the levels. For example, if you want “c” to be first (e.g., because it refers to the control group), set the order as follows:  A <- factor(A, levels = c("c","a","b"))

There are a variety of good utility functions that you can use to check how R classified your data.

```{r echo=TRUE}
str(mammals)            
```

*Reclassifying your data*
If your data have not been classified correctly you can convert among types.  However, its important to recognize that if you are converting factors to numeric values or integers, you must first convert to the data to characters. Converting factors directly to numeric or integer data can lead to unwanted outcomes.
```{r echo=TRUE, warning=TRUE}
mammals$x <- as.character(mammals$x)  
mammals$x <- as.factor(mammals$x)     
mammals$x <- as.numeric(as.character(mammals$x)) 
```

*Saving your data frame*
You can also save a manipulated version of a data frame or a new set of data (e.g. from a simulation) as a csv file.

```{r echo=TRUE, warning=TRUE}
write.csv(mammals,file="~/GitHub/mammals.csv",rownames=FALSE)
         
```

**Tips for creating your Data File so that it plays nicely with R**

It is easiest to enter data using a spreadsheet and use the standard approach of columns for variables and rows for individual sampling units. Carefully considering what you should put into your spreadsheet may help save you some time and frustration when it.

  a. Column names should be brief but informative names for variable using plain text 
  b. Detailed explanations of variables can be kept in a separate metadata text file). 
  c. You should avoid spaces in variable names – use a dot or underscore instead (e.g., mass.grams or mass_grams). 
  d. Leave missing cells (i.e. no data) blank and avoid non-numeric characters in columns of numeric data. 

If you enter in a character for missing data, R will assume that the entire column is non-numeric. For example, avoid using a question mark “12.67?” to indicate a number you are not sure about. 
  
  e. Do not put in a zero for missing data...zeros are assumed to be data!
  f. Dates should be in international format (YYYY-MM-DD) or use separate columns for year, month and day.
  g. Avoid commas in your data set entirely, because they are column delimiters in your .csv file.

There are two common layouts for data: "Long" vs "wide" layouts.  

*Wide layout*
Plot    Site      species1   species2   species3
 1        A           0          12         4
 2        A          88           2         0
 3        B          12           4         1   
...

*Long layout*
Plot   Site  Species Number
 1      A      1      0
 1      A      2     12
 1      A      3      4
 2      A      1     88
 2      A      2      2
 2      A      3      0
 3      B      1     12
 3      B      2      4
 3      B      3      1
...

In general a “long” layout is recommended for conducting analyses in R, rather than a “wide” layout. However the "wide layout" can sometimes be more feasible for accurate data entry. You can convert between these, however before learning how to do that there are a some important utility function for data wrangling that you need to be familiar with. 


**Data wrangling with dplyr and tidyr**

The package `dplyr` has been said to be the most perfectly suited package for streamlining workflow for real analytics.  Its utility comes from the fact that it uses a combination of five primary verbs (i.e. functions or commands) and a process called chaining.

The five verbs are
`filter()`
`select()`
`mutate()`
`arrange()`
`summarize()`

The `filter()` command allows you to subset a dataset only retaining data for rows that you are interested in.  For example, we will use one of `R's` built in data sets on diamond cuts to illustrate different aspects of the packages utilities. Lets load and examine the data set first.

```{r echo=TRUE, warning=TRUE}
library(dplyr)
library(ggplot2)
str(diamonds)
head(diamonds)
```
Okay, lets use the filtering command to subset these data so that we only retain values for the cases where `cut` variable is `"ideal"`.
```{r echo=TRUE, warning=TRUE}
idl.diamonds=filter(diamonds,cut=="Ideal")
idl.diamonds
```

Similarly we can choose only a subset of the columns (variables) in the data frame. For example, we may want to simplify things by creating a new working data frame that only has the variables of interest for a given analysis.  In this case lets create a data set that only retains the variables:"cut","carat","color","price",and "clarity".  This is easily accomplished using the `select()` command.

```{r echo=TRUE, warning=TRUE}
sub.diamonds=select(idl.diamonds,carat,cut,color,price,clarity)
sub.diamonds
```

Another very common task in data analytic or any programming task is adding variables.  We can do this using the `mutate()` command.  For example we might want to add a variable that reflects the costs of diamonds per carat of quality.

```{r echo=TRUE, warning=TRUE}
price.per=mutate(sub.diamonds,price_per=price/carat)
price.per
```

`arrange()` does the same thing as the `order()` function we learned earlier, but using `arrange()'makes the syntax much simpler.  
We will use a simple made up data set to illustrate this function.
```{r echo=TRUE, warning=TRUE}
scramble=data.frame(num_var=c(2,3,5,1,4))
arrange(scramble,num_var)
arrange(scramble,desc(num_var))
```

Finally the summarize() command does exactly what it sounds like it does...it allows you to generate summaries or summarized versions of the data.  For example we can use it to calculate a simple mean using our subset data set from above.
```{r echo=TRUE, warning=TRUE}
summarize(sub.diamonds,avg_price=mean(price,na.rm=TRUE))
```

We can also use this to generate more complicated summaries of the data using a sub function called `group_by()`.  For example we can go back to the original diamonds data set and summarize the data by calculating means according to all cut types.
```{r echo=TRUE, warning=TRUE}
head(diamonds)
d1=group_by(diamonds,cut,color)
summarize(d1, avg_price = mean(price, na.rm = TRUE),sd.price=sd(price,na.rm=TRUE))
```

The real power of this library is not fully realized however until you start `chaining` commands together.  You can chain together different verbs of `dplyr` using the `%>%` operator.  All this operator does is allow you to connect commands together so that the output of one command becomes the input for the next down a chain.  For example we can do all the steps above on the diamonds data set in a  single chain of commands.

```{r echo=TRUE, warning=TRUE}
final.diamonds= diamonds %>%
                filter(cut=="Ideal") %>%
                select(carat, cut, color, price, clarity) %>%
                mutate(price_per_carat = price/carat)
final.diamonds
```
This chained set of syntax literally says:
– “Take the diamonds data set’ ”
– “Then filter it, keeping only the rows where ‘cut’ equals ‘Ideal’ ”
– “Then select specific variables, ‘carat’, ‘cut’, ‘color’, ‘price, ‘clarity’ ”
– “Then create a new variable, ‘price_per_carat’ using ‘mutate()’ ”

Finally, `dplyr` can also be a powerful tool for data exploration when paired with `ggplot` (more on this in the second part of this tutorial) Its power comes from the fact that you can chain together dplyr commands and ggplot commands. For example we can create a box plot for just the ideal diamonds by

```{r}
  diamonds %>%                                        # Start with the 'diamonds' dataset
  filter(cut == "Ideal") %>%                        # Then, filter down to rows where cut == Ideal
  ggplot(aes(x=color,y=price)) +                     # Then, plot using ggplot
  geom_boxplot()      
diamonds %>%                                        # Start with the 'diamonds' dataset
  filter(cut == "Premium") %>%                        # Then, filter down to rows where cut == Ideal
  ggplot(aes(x=carat,y=price)) +                     # Then, plot using ggplot
  geom_point()
```

or a histogram by

```{r}
diamonds %>%                                        # Start with the 'diamonds' dataset
  filter(cut == "Ideal") %>%                        # Then, filter down to rows where cut == Ideal
  ggplot(aes(price)) +                            # Then, plot using ggplot
    geom_histogram() +                              # and plot histograms
    facet_wrap(~ color)                             # in a 'small multiple' plot, broken out by 'color'
```

**Wide to Long and Back again**
In R most functions expect data to be in a long format rather than a wide format, however ease of data entry and data formatted for some other statistical software (e.g. SPSS) may result in data in the wide format. To deal with this problem there are some nifty methods using the `gather()` and `spread()` functions from the `tidyr` library.

If you do not already have tidy R you will need to install it.

First,  we will use the below code that I borrowed from to generate data in a wide and long format.  The data are exactly the same for both formats. Then we will convert each to the other format below.

First we will make the wide formatted data....take note on the generation of these data...

```{r}
wide <- read.table(header=TRUE, text='
 subject sex control cond1 cond2
       1   M     7.9  12.3  10.7
       2   F     6.3  10.6  11.1
       3   F     9.5  13.1  13.8
       4   M    11.5  13.4  12.9
')
# Make sure the subject column is a factor
wide$subject <- factor(wide$subject)
str(wide)
wide
```

And now the same data in the long format.

```{r}
long <- read.table(header=TRUE, text='
 subject sex condition measurement
       1   M   control         7.9
       1   M     cond1        12.3
       1   M     cond2        10.7
       2   F   control         6.3
       2   F     cond1        10.6
       2   F     cond2        11.1
       3   F   control         9.5
       3   F     cond1        13.1
       3   F     cond2        13.8
       4   M   control        11.5
       4   M     cond1        13.4
       4   M     cond2        12.9
')
# Make sure the subject column is a factor
long$subject <- factor(long$subject)
str(long)
```


To convert the data from wide to long format we will use the `gather` function.  This function has several key pieces of input (arguments) that are needed. These are

`gather(data,key,value,...sources,factor key)`
  # - data: Data object
  # - key: Name of new key column (made from names of data columns)
  # - value: Name of new value column
  # - ...: Names of source columns that contain values
  # - factor_key: Treat the new key column as a factor (instead of character vector)
  
So to implement we just need to run:
```{r}
require(tidyr)
wide_to_long <- gather(wide, condition, measurement, control:cond2, factor_key=TRUE)
wide_to_long
```

In this example, the source columns that are gathered are specified with `control:cond2`. This means to use all the columns, positional, between `control` and `cond2`. Another way of doing it is to name the columns individually, as in:

```{r}
wide_to_long <- gather(wide, condition, measurement, control, cond1, cond2, factor_key=TRUE)
wide_to_long
```

In some cases you may want to use `gather()` internally in some larger function and so you will want to use variables containing column names rather than the column names themselves. To do this use the `gather_()` function instead.

```{r}
keycol <- "condition"
valuecol <- "measurement"
gathercols <- c("control", "cond1", "cond2")
gather_(wide, keycol, valuecol, gathercols)
```

To convert our data from the long format to the wide format we do the same steps except we use the `spread` function instead of the `gather` function.

```{r}
long_to_wide <- spread(wide_to_long, condition, measurement)
long_to_wide
```

**Contrasting base R and dplyr**

Below are some useful data manipulation approaches using base R functionality and the new functions. It is useful to learn both because the base R version gives a more intuitive understanding of what th code is actually doing, where as the new functionality of dply provides some efficient tools.  I often use these interchangeably depending on the application, I prefer one or the other.

*Transform a column (variable) within a data frame*

For example, log transform a variable named mass.grams and save the result as a new variable named logsize in the data frame. (log yields the natural log, whereas the function log10 yields log base 10.)

```{r}
mammals$logsize <- log(mammals$mass.grams)            # base R
str(mammals)
mammals <- mutate(mammals, log10size = log10(mass.grams)) # using the dplyr package
str(mammals)
```



*Delete a variable from data frame*

For example, to delete the variable species from mydata, use
```{r}
mammals$species <- NULL # Base R -- NULL must be upper case
mammals <- select(mammals, -species) # dplyr method
```

*Extract a data subset*

There are several ways. One is to use indicators inside square brackets using the following format: mydata[rows, columns]. Be sure to look after each line below to see what the commands did to the data set

```{r echo=TRUE}
mammals
newdata <- mammals[ , c(2,3)]   # all rows, columns 2 and 3 only;
newdata
newdata <- mammals[ , -1] # all rows, leave out first column
newdata
newdata <- mammals[1:3, 1:2]    # first three rows, first two column
newdata
```


Alternatively you can use logical statements and variable names within the square brackets.

```{r}
newdata <- mammals[mammals$continent == "AF" & mammals$logsize < 25,  c("continent","status","order")]
newdata
```


The subset command in base R is easy to use to extract rows and columns. Use the select argument to select columns (variables). For example, to pull out rows corresponding to continent AF with logsize < 25, and the three variables, "continent","status","order" you could  use the following.

```{r}
newdata <- subset(mammals, continent == "AF" & mass.grams < 25, select = c(continent,status,order))
newdata
```


You can also use dplyr’s filter and select commands. Use select to extract variables (columns), and use filter to select rows, as in the following examples.

```{r}
# extract rows
locations <- filter(mammals, continent == "AF")
# extract columns
newdata <- select(mammals, continent,status,order) 
newdata
```


*Sort and order the rows*

To re-order the rows of a data frame mydata to correspond to the sorted order of one of its variables, say x, use

```{r}
mammals.x <- mammals[order(mammals$x), ]  # base R
mammals.x <- arrange(mammals, x)         # dplyr method
```


You can also use dplyr’s filter and select commands. Use select to extract variables (columns), and use filter to select rows, as in the following examples.

```{r}
# extract rows
locations <- filter(mammals, continent == "AF")
# extract columns
newdata <- select(mammals, continent,status,order)
newdata
```


*Sort and order the rows*

To re-order the rows of a data frame mydata to correspond to the sorted order of one of its variables, say x, use

```{r}
mammals.x <- mydata[order(mammals$x), ]  # base R
mammals.x <- arrange(mammals, x)         # dplyr method
```
